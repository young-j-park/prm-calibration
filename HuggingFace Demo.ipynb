{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85e0998-ef90-481f-984c-7f021b433a96",
   "metadata": {},
   "source": [
    "# How to load calibration dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6a3ca3-ff4d-4263-a5d5-6f2b90ad921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/home/lab/.conda/envs/prm-calibration-v2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = \"math500\"\n",
    "policy_model_id_safe = \"Llama-3.2-1B-Instruct\"\n",
    "\n",
    "ds = load_dataset(\"young-j-park/prm_calibration\", data_files=f\"{dataset}/{policy_model_id_safe}/data.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4041fb8-3fe2-44c9-be07-c9330ad26ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: A reflection takes $\\begin{pmatrix} 5 \\\\ 0 \\end{pmatrix}$ to $\\begin{pmatrix} 4 \\\\ 3 \\end{pmatrix}.$  Which vector does the reflection take $\\begin{pmatrix} -2 \\\\ 3 \\end{pmatrix}$ to?\n",
      "Prefix: ## Step 1: Find the midpoint of the vector $\\begin{pmatrix} 5 \\\\ 0 \\end{pmatrix}$ and $\\begin{pmatrix} 4 \\\\ 3 \\end{pmatrix}$.\n",
      "The midpoint formula is given by $\\left( \\frac{x_1+x_2}{2}, \\frac{y_1+y_2}{2} \\right)$.\n",
      "\n",
      "## Step 2: Calculate the midpoint using the given vectors.\n",
      "Midpoint = $\\left( \\frac{5+4}{2}, \\frac{0+3}{2} \\right) = \\left( \\frac{9}{2}, \\frac{3}{2} \\right)$.\n",
      "\n",
      "## Step 3: Determine the vector perpendicular to the line of reflection.\n",
      "This can be found by calculating the vector $\\begin{pmatrix} 5 \\\\ 0 \\end{pmatrix} - \\left( \\frac{9}{2}, \\frac{3}{2} \\right) = \\begin{pmatrix} 5-\\frac{9}{2} \\\\ 0-\\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix}$.\n",
      "\n",
      "## Step 4: Calculate the projection of $\\begin{pmatrix} -2 \\\\ 3 \\end{pmatrix}$ onto the perpendicular vector.\n",
      "This is given by the dot product of $\\begin{pmatrix} -2 \\\\ 3 \\end{pmatrix}$ and $\\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix}$ divided by the magnitude of the perpendicular vector squared.\n",
      "\n",
      "## Step 5: Calculate the projection.\n",
      "Projection = $\\frac{\\begin{pmatrix} -2 \\\\ 3 \\end{pmatrix} \\cdot \\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix}}{\\left(\\left|\\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix}\\right|^2\\right)}$ = $\\frac{-2\\cdot\\frac{1}{2}+3\\cdot\\left(-\\frac{3}{2}\\right)}{\\left(\\frac{1}{4}+\\frac{9}{4}\\right)} = \\frac{-1-9}{2} = \\frac{-10}{2} = -5$.\n",
      "\n",
      "## Step 6: Find the reflection point by using the projection as the midpoint.\n",
      "The reflection point of $\\begin{pmatrix} -2 \\\\ 3 \\end{pmatrix}$ is twice the projection minus the original point. Therefore, it equals $2\\left(-5\\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix}\\right) + \\begin{pmatrix} -2 \\\\ 3 \\end{pmatrix}$.\n",
      "\n",
      "## Step 7: Calculate the reflection point.\n",
      "Reflection point = $2\\left(-5\\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix}\\right) + \\begin{pmatrix} -2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} -5\\cdot\\frac{1}{2}-2 \\\\ -5\\cdot\\left(-\\frac{3}{2}\\right)+3 \\end{pmatrix} = \\begin{pmatrix} -\\frac{5}{2} -2 \\\\ \\frac{15}{2}+3 \\end{pmatrix} = \\begin{pmatrix} -\\frac{5}{2} -\\frac{4}{2} \\\\ \\frac{15}{2}+\\frac{6}{2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{9}{2} \\\\ \\frac{21}{2} \\end{pmatrix}$.\n",
      "\n",
      "## Step 8: Simplify the reflection point.\n",
      "Final reflection point = $\\begin{pmatrix} -\\frac{9}{2} \\\\ \\frac{21}{2} \\end{pmatrix}$.\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 38\n",
    "x = ds[sample_idx]\n",
    "\n",
    "question = x[\"question\"]\n",
    "reasoning_prefix = x[\"reasoning_prefix\"]\n",
    "success_prob = x[\"success_prob\"]\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Prefix: {reasoning_prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c65341c-7247-4502-ba65-ea82340128f8",
   "metadata": {},
   "source": [
    "# How to load PRM from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b65c40-71ee-4050-9256-e8c27113cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████| 4/4 [00:02<00:00,  1.50it/s]\n",
      "Some weights of the model checkpoint at Qwen/Qwen2.5-Math-PRM-7B were not used when initializing Qwen2ForProcessRewardModel: {'lm_head.weight'}\n",
      "- This IS expected if you are initializing Qwen2ForProcessRewardModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Qwen2ForProcessRewardModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from prm import load_prm\n",
    "\n",
    "prm_model_id = \"Qwen/Qwen2.5-Math-PRM-7B\"\n",
    "prm = load_prm(prm_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aab00c-4aa2-46fe-bfda-f257026daf22",
   "metadata": {},
   "source": [
    "### Uncalibrated Quantile Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb147ae-619c-4947-b672-489ca4f9cb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=3584, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original prm: 3584 -> 2 [good, bad]\n",
    "prm.model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f22fdecb-c4a3-4710-a78f-7bfae684abc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm.quantile_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72691d2-84b0-48a3-a154-9a674c0da312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "1it [00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Probability (Ground Truth): 0.0\n",
      "Uncalibrated PRM Reward (Estimation): 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uncalibrated_scores = prm.score([question], [[reasoning_prefix]])\n",
    "prefix_reward = uncalibrated_scores[0][0][-1]  # we only need the last score\n",
    "\n",
    "print(\"Success Probability (Ground Truth):\", success_prob)\n",
    "print(\"Uncalibrated PRM Reward (Estimation):\", prefix_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b375d17-d16f-416d-957a-18cc21276760",
   "metadata": {},
   "source": [
    "## Attatch quantile heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc329f6b-15a7-486b-ad6f-470a0141127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=3584, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calibrated prm: 3584 -> 3 [0.1, 0.5, 0.9]\n",
    "prm.convert_to_quantile_regression_head(M=3)\n",
    "prm.model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73300ad7-337a-4b4f-80fe-1818c821bfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm.quantile_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2bf78-0f25-43ee-b01b-bccf6e3fdbd9",
   "metadata": {},
   "source": [
    "## Load from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "435b3179-285b-42f7-a2c5-e37475ac1dc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "prm_model_id_safe = prm_model_id.split(\"/\")[-1]\n",
    "\n",
    "peft_model_id = f\"young-j-park/{prm_model_id_safe}-calibrated-{policy_model_id_safe}\"\n",
    "peft_model = PeftModel.from_pretrained(prm.model, peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b0bc4-594a-4f99-9d18-76fd6d7807ed",
   "metadata": {},
   "source": [
    "### Calibrated Quantile Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da03d935-c38e-466e-9a4c-c0ea9fada85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 27.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Probability (Ground Truth): 0.0\n",
      "10% Quantile (Estimation): 7.486343383789062e-05\n",
      "50% Quantile (Estimation): 0.0025482177734375\n",
      "90% Quantile (Estimation): 0.064453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "calibrated_scores = prm.score([question], [[reasoning_prefix]])\n",
    "prefix_reward_quantiles = calibrated_scores[0][0][-1]  # we only need the last score\n",
    "\n",
    "print(\"Success Probability (Ground Truth):\", success_prob)\n",
    "print(\"10% Quantile (Estimation):\", prefix_reward_quantiles[0])\n",
    "print(\"50% Quantile (Estimation):\", prefix_reward_quantiles[1])\n",
    "print(\"90% Quantile (Estimation):\", prefix_reward_quantiles[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prm-calibration-v2)",
   "language": "python",
   "name": "prm-calibration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
